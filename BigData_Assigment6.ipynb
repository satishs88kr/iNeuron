{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d839b41c",
   "metadata": {},
   "source": [
    "# Working with RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to create an RDD from a local data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99072adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(appName=\"AppName\")\n",
    "\n",
    "data_file = \"C:\\Users\\satis\\Downloads\\iNeuron_assigment\\BIG_DATA/file.txt\"\n",
    "rdd = sc.textFile(data_file)\n",
    "\n",
    "word_counts = rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "for i, b in word_counts.collect():\n",
    "    print(f\"{i}: {b}\")\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293850cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to create an RDD from a local data source.Implement transformations and actions on the RDD to perform data processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(appName=\"AppName\")\n",
    "\n",
    "data_file = \"C:\\Users\\satis\\Downloads\\iNeuron_assigment\\BIG_DATA/file.txt\"\n",
    "rdd = sc.textFile(data_file)\n",
    "\n",
    "filtered_rdd = rdd.filter(lambda line: \"error\" in line)\n",
    "err = filtered_rdd.count()\n",
    "fir = filtered_rdd.first()\n",
    "\n",
    "print(\"Number of errors:\", err)\n",
    "print(\"First error:\", fir)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to create an RDD from a local data source.Analyze and manipulate data using RDD operations such as map, filter, reduce, or aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf37ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(appName=\"AppName\")\n",
    "\n",
    "data_file = \"C:\\Users\\satis\\Downloads\\iNeuron_assigment\\BIG_DATA/file.txt\"\n",
    "rdd = sc.textFile(data_file)\n",
    "\n",
    "ln_cnt = rdd.count()\n",
    "\n",
    "wrd_cnt = rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "fil_lin = rdd.filter(lambda line: \"error\" in line)\n",
    "\n",
    "total_wrd_cnt = word_counts.map(lambda x: x[1]).reduce(lambda a, b: a + b)\n",
    "\n",
    "print(\"Number of lines:\", ln_cnt)\n",
    "print(\"Word counts:\", wrd_cnt.collect())\n",
    "print(\"Filtered lines:\", fil_lin.collect())\n",
    "print(\"Total word count:\", total_wrd_cnt)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ea12b",
   "metadata": {},
   "source": [
    "# Spark DataFrame Operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to create an RDD from a local data source.Write a Python program to load a CSV file into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7518c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AppName\").getOrCreate()\n",
    "\n",
    "csv_file = \"C:\\Users\\satis\\Downloads\\iNeuron_assigment\\BIG_DATA/a.csv\"\n",
    "df = spark.read.csv(csv_file, header=True, inferSchema=True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae927aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to create an RDD from a local data source.Perform common DataFrame operations such as filtering, grouping, or joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AppName\").getOrCreate()\n",
    "\n",
    "data_file = \"C:\\Users\\satis\\Downloads\\iNeuron_assigment\\BIG_DATA/a.csv\"\n",
    "rdd = spark.sparkContext.textFile(data_file)\n",
    "\n",
    "df = spark.createDataFrame(rdd, [\"id\", \"name\", \"rollno\"])\n",
    "\n",
    "filtered_df = df.filter(df.column1 > 10)\n",
    "\n",
    "grouped_df = df.groupBy(\"name\").agg({\"rollno\": \"sum\"})\n",
    "\n",
    "other_df = spark.createDataFrame([(1, \"value1\"), (2, \"value2\")], [\"name\", \"rollno\"])\n",
    "joined_df = df.join(other_df, \"rollno\")\n",
    "\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to create an RDD from a local data source.Apply Spark SQL queries on the DataFrame to extract insights from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4658be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"AppName\").getOrCreate()\n",
    "\n",
    "data_file = \"C:\\Users\\satis\\Downloads\\iNeuron_assigment\\BIG_DATA/a.csv\"\n",
    "rdd = spark.sparkContext.textFile(data_file)\n",
    "df = spark.createDataFrame(rdd, [\"id\", \"name\", \"string\"])\n",
    "df.createOrReplaceTempView(\"satish_table\")\n",
    "qur = spark.sql(\"SELECT column1, COUNT(*) as count FROM satish_table GROUP BY column1 ORDER BY count DESC\")\n",
    "qur.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
